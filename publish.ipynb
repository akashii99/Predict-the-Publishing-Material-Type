{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "colab_type": "code",
    "id": "g1I1V2w2zkZj",
    "outputId": "187df57b-a924-463b-baa0-754c8dfff6bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "   ID UsageClass CheckoutType  CheckoutYear  CheckoutMonth  Checkouts  \\\n",
      "0   1   Physical      Horizon          2005              4          1   \n",
      "1   2   Physical      Horizon          2005              4          1   \n",
      "2   3   Physical      Horizon          2005              4          3   \n",
      "3   4   Physical      Horizon          2005              4          1   \n",
      "4   5   Physical      Horizon          2005              4          1   \n",
      "\n",
      "                                               Title               Creator  \\\n",
      "0                                         Tidal wave                   NaN   \n",
      "1                     London holiday / Richard Peck.  Peck, Richard, 1934-   \n",
      "2  Cinco de Mayo : celebrating Hispanic pride / C...      Gnojewski, Carol   \n",
      "3                                          Annapolis                   NaN   \n",
      "4                                  As a man thinketh                   NaN   \n",
      "\n",
      "                                            Subjects           Publisher  \\\n",
      "0             Tsunamis, Tsunamis Juvenile literature                 NaN   \n",
      "1                                                NaN             Viking,   \n",
      "2  Cinco de Mayo Mexican holiday History Juvenile...  Enslow Publishers,   \n",
      "3  War stories, Historical fiction, Domestic fict...                 NaN   \n",
      "4                               Thought and thinking                 NaN   \n",
      "\n",
      "  PublicationYear MaterialType  \n",
      "0             NaN         BOOK  \n",
      "1           1998.         BOOK  \n",
      "2          c2002.         BOOK  \n",
      "3             NaN         BOOK  \n",
      "4             NaN         BOOK  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31653 entries, 0 to 31652\n",
      "Data columns (total 12 columns):\n",
      "ID                 31653 non-null int64\n",
      "UsageClass         31653 non-null object\n",
      "CheckoutType       31653 non-null object\n",
      "CheckoutYear       31653 non-null int64\n",
      "CheckoutMonth      31653 non-null int64\n",
      "Checkouts          31653 non-null int64\n",
      "Title              31653 non-null object\n",
      "Creator            8516 non-null object\n",
      "Subjects           29890 non-null object\n",
      "Publisher          9737 non-null object\n",
      "PublicationYear    9722 non-null object\n",
      "MaterialType       31653 non-null object\n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 2.9+ MB\n",
      "None\n",
      "24755\n",
      "6731\n",
      "['BOOK' 'SOUNDDISC' 'VIDEOCASS' 'VIDEODISC' 'SOUNDCASS' 'MUSIC' 'MIXED'\n",
      " 'CR']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df = pd.read_csv('train_file.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df['Subjects'].nunique())\n",
    "print(df['Creator'].nunique())\n",
    "print(df['MaterialType'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "PAIlArNqztJR",
    "outputId": "f5874eed-251e-483b-d5ec-6a2d469f7ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID UsageClass CheckoutType  CheckoutYear  CheckoutMonth  Checkouts  \\\n",
      "0  31654   Physical      Horizon          2005              4          1   \n",
      "1  31655   Physical      Horizon          2005              4          2   \n",
      "2  31656   Physical      Horizon          2005              4          2   \n",
      "3  31657   Physical      Horizon          2005              4          2   \n",
      "4  31658   Physical      Horizon          2005              4          2   \n",
      "\n",
      "                                               Title  \\\n",
      "0                           Footprints at the window   \n",
      "1                    Seven brides for seven brothers   \n",
      "2  History [sound recording] / Loudon Wainwright ...   \n",
      "3                 Doing big business on the internet   \n",
      "4                       Lets learn how to dance shag   \n",
      "\n",
      "                          Creator  \\\n",
      "0                             NaN   \n",
      "1                             NaN   \n",
      "2  Wainwright, Loudon, III, 1946-   \n",
      "3                             NaN   \n",
      "4                             NaN   \n",
      "\n",
      "                                            Subjects  Publisher  \\\n",
      "0            England Fiction, Space and time Fiction        NaN   \n",
      "1  Video recordings for the hearing impaired, Mus...        NaN   \n",
      "2                            Popular music 1991 2000  Charisma,   \n",
      "3  Internet, Internet advertising, Information ne...        NaN   \n",
      "4                       Shag Dance, Ballroom dancing        NaN   \n",
      "\n",
      "  PublicationYear  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2          p1992.  \n",
      "3             NaN  \n",
      "4             NaN  \n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('test_file.csv')\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Filling the missing data \n",
    "X = Features\n",
    "Y = Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "LxdKGzVpzxY4",
    "outputId": "c4c19ad5-54c5-4577-fc78-ac59ee51538d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31653 entries, 0 to 31652\n",
      "Data columns (total 12 columns):\n",
      "ID                 31653 non-null int64\n",
      "UsageClass         31653 non-null object\n",
      "CheckoutType       31653 non-null object\n",
      "CheckoutYear       31653 non-null int64\n",
      "CheckoutMonth      31653 non-null int64\n",
      "Checkouts          31653 non-null object\n",
      "Title              31653 non-null object\n",
      "Creator            31653 non-null object\n",
      "Subjects           31653 non-null object\n",
      "Publisher          31653 non-null object\n",
      "PublicationYear    31653 non-null object\n",
      "MaterialType       31653 non-null object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df['Subjects'].fillna(\"Others\", inplace=True)\n",
    "#print(df.info())\n",
    "df['Publisher'].fillna(\"Extras\", inplace=True)\n",
    "#print(df.info())\n",
    "\n",
    "df['Creator'].fillna(\"Single\", inplace=True)\n",
    "df['PublicationYear'].fillna(\"Not_Mentioned\", inplace=True)\n",
    "\n",
    "\n",
    "df['Checkouts'] = df['Checkouts'].astype('object')\n",
    "print(df.info())\n",
    "\n",
    "df.loc[df['Publisher'].str.contains('viking'), 'Publisher'] = 'vikings'\n",
    "df.loc[df['Subjects'].str.contains('viking'), 'Subjects'] = 'vikings'\n",
    "df.loc[df['Title'].str.contains('viking'), 'Title'] = 'vikings'\n",
    "df.loc[df['Creator'].str.contains('viking'), 'Creator'] = 'vikings'\n",
    "\n",
    "X = df.Subjects + df.Publisher + df['PublicationYear']\n",
    "Y = df['MaterialType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FPCYYFXLzii"
   },
   "source": [
    "# Text Preprocessing: Cleaning the data\n",
    "\n",
    "1. Removing stopwords\n",
    "2. Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJ0ZRSwtz0qg"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.str.strip().str.lower()\n",
    "    text = text.str.translate(str.maketrans('', '', '():,.?\\'\"/+-_[]&%$@'))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SlD8qAcez3we"
   },
   "outputs": [],
   "source": [
    "X = clean_text(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-8ycN4nMG4g"
   },
   "source": [
    "# Convering text data into vectors using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WG7dvSvVz5sy"
   },
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode', token_pattern=r'\\w{1,}', analyzer='word', ngram_range=(1,1))\n",
    "#vectors1 = vectorizer.fit_transform(X)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectors1 = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-biRnyVa6WmI"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(vectors1,Y, test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGxGm3FS4nCd"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDLIlk-xz7-E"
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Il5ljoO0RKR"
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "hMDyuscv45F2",
    "outputId": "4d86a120-5fd5-48c8-ef49-b4f5314957c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=MultinomialNB(alpha=0.03, class_prior=None, fit_prior=True),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.4, n_estimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=1075, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seed = 1075\n",
    "np.random.seed(seed)\n",
    "bagging_clf = BaggingClassifier(clf, max_samples=0.4, random_state=seed)\n",
    "bagging_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UpG3izS66s_s",
    "outputId": "3b20d556-d927-443e-c165-24679daa384d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VIDEOCASS' 'BOOK' 'BOOK' ... 'BOOK' 'BOOK' 'BOOK']\n"
     ]
    }
   ],
   "source": [
    "Y_pred=bagging_clf.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "dvEWWnMV7Bax",
    "outputId": "cb51538b-c15a-4e6b-f0a9-5bfb49d3a431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7730216395514137\n",
      "Confusion Matrix:\n",
      " [[3610   83  166   35  315   72   76   27]\n",
      " [   6   11    1    0    1    0    0    0]\n",
      " [  59    0    4    1    0    1    0    0]\n",
      " [   0    0    0   13    0   14    0    0]\n",
      " [ 134    0    0    0   51    7    5    2]\n",
      " [  49    0    4    4   37  715    6    0]\n",
      " [  96    3   11    1    4   10  338   66]\n",
      " [  18    1    2    2    5   10  103  152]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Score:\",bagging_clf.score(X_test,Y_test))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4asHUHS60HH-"
   },
   "outputs": [],
   "source": [
    "#boosting = AdaBoostClassifier(base_estimator=clf, n_estimators= 10)   \n",
    "#boosting.fit(vectors1, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "ELjoM5AU0XO8",
    "outputId": "eb340893-0f1e-4b92-d95e-57297edda8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31653 entries, 0 to 31652\n",
      "Data columns (total 12 columns):\n",
      "ID                 31653 non-null int64\n",
      "UsageClass         31653 non-null object\n",
      "CheckoutType       31653 non-null object\n",
      "CheckoutYear       31653 non-null int64\n",
      "CheckoutMonth      31653 non-null int64\n",
      "Checkouts          31653 non-null object\n",
      "Title              31653 non-null object\n",
      "Creator            31653 non-null object\n",
      "Subjects           31653 non-null object\n",
      "Publisher          31653 non-null object\n",
      "PublicationYear    31653 non-null object\n",
      "MaterialType       31653 non-null object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df2['Subjects'].fillna(\"Others\", inplace=True)\n",
    "#print(df.info())\n",
    "df2['Publisher'].fillna(\"Extras\", inplace=True)\n",
    "#print(df.info())\n",
    "\n",
    "df2['Creator'].fillna(\"Single\", inplace=True)\n",
    "df2['PublicationYear'].fillna(\"Not_Mentioned\", inplace=True)\n",
    "\n",
    "df2['Checkouts'] = df2['Checkouts'].astype('object')\n",
    "print(df.info())\n",
    "\n",
    "df2.loc[df2['Publisher'].str.contains('viking'), 'Publisher'] = 'vikings'\n",
    "df2.loc[df2['Subjects'].str.contains('viking'), 'Subjects'] = 'vikings'\n",
    "df2.loc[df2['Title'].str.contains('viking'), 'Title'] = 'vikings'\n",
    "\n",
    "X1 = df2.Subjects + df2.Publisher + df2.PublicationYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW5gFVV41CMC"
   },
   "outputs": [],
   "source": [
    "X1 = clean_text(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyzVIHYC1IPB"
   },
   "outputs": [],
   "source": [
    "vectors_test1 = vectorizer.transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "647e1f9V1JuO",
    "outputId": "b338abd1-4e0a-44b9-8b40-8da4df72b92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOOK' 'VIDEOCASS' 'SOUNDDISC' ... 'BOOK' 'VIDEOCASS' 'SOUNDDISC']\n"
     ]
    }
   ],
   "source": [
    "pred1 = bagging_clf.predict(vectors_test1)\n",
    "print(pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hyApyT8PLYLM"
   },
   "source": [
    "**Saving these predictions to a csv file**\n",
    "\n",
    "Creating a new dataframe df3 and storing these predictions of MaterialType in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "BgFrSLu-1e5a",
    "outputId": "bdbf0dce-8e97-4aae-d9b9-f07b7fe724c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID MaterialType\n",
      "0  31654         BOOK\n",
      "1  31655    VIDEOCASS\n",
      "2  31656    SOUNDDISC\n",
      "3  31657         BOOK\n",
      "4  31658    VIDEOCASS\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame()\n",
    "df3['ID'] = df2['ID']\n",
    "df3['MaterialType'] = pred1\n",
    "\n",
    "print(df3.head())\n",
    "\n",
    "df3.to_csv('Submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "publish.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
